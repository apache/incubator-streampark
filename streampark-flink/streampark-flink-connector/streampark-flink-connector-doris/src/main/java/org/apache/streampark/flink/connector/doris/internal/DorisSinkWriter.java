/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.streampark.flink.connector.doris.internal;

import org.apache.streampark.common.enums.Semantic;
import org.apache.streampark.common.util.ThreadUtils;
import org.apache.streampark.connector.doris.conf.DorisConfig;
import org.apache.streampark.flink.connector.doris.bean.DorisSinkBufferEntry;
import org.apache.streampark.flink.connector.doris.bean.LoadStatusFailedException;

import org.apache.flink.api.common.functions.RuntimeContext;
import org.apache.flink.metrics.Counter;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.io.Serializable;
import java.nio.charset.StandardCharsets;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;

public class DorisSinkWriter implements Serializable {
  private static final long serialVersionUID = 1L;
  private static final Logger LOG = LoggerFactory.getLogger(DorisSinkWriter.class);

  private final DorisConfig dorisConfig;
  private final DorisStreamLoader streamLoader;

  private ScheduledExecutorService schedule;
  private ScheduledFuture<?> scheduledFuture;

  private transient Counter totalFlushBytes;
  private transient Counter totalFlushRows;
  private transient Counter totalFlushTime;
  private transient Counter totalFlushTimeWithoutRetries;
  private transient Counter totalFlushSucceededTimes;
  private transient Counter totalFlushFailedTimes;

  private final Map<String, DorisSinkBufferEntry> bufferMap = new ConcurrentHashMap<>();
  private final Long timeout = 3000L;
  private volatile boolean closed = false;
  private volatile boolean flushThreadAlive = false;
  private volatile Throwable flushException;

  final LinkedBlockingDeque<DorisSinkBufferEntry> flushQueue = new LinkedBlockingDeque<>(10);

  private static final String COUNTER_TOTAL_FLUSH_BYTES = "totalFlushBytes";
  private static final String COUNTER_TOTAL_FLUSH_ROWS = "totalFlushRows";
  private static final String COUNTER_TOTAL_FLUSH_COST_TIME_WITHOUT_RETRIES =
      "totalFlushTimeNsWithoutRetries";
  private static final String COUNTER_TOTAL_FLUSH_COST_TIME = "totalFlushTimeNs";
  private static final String COUNTER_TOTAL_FLUSH_SUCCEEDED_TIMES = "totalFlushSucceededTimes";
  private static final String COUNTER_TOTAL_FLUSH_FAILED_TIMES = "totalFlushFailedTimes";

  private final Semantic semantic;

  public DorisSinkWriter(DorisConfig dorisConfig) {
    this.streamLoader = new DorisStreamLoader(dorisConfig);
    this.dorisConfig = dorisConfig;
    semantic = Semantic.of(dorisConfig.semantic());
  }

  public void setRuntimeContext(RuntimeContext runtimeCtx) {
    totalFlushBytes = runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_BYTES);
    totalFlushRows = runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_ROWS);
    totalFlushTime = runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_COST_TIME);
    totalFlushTimeWithoutRetries =
        runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_COST_TIME_WITHOUT_RETRIES);
    totalFlushSucceededTimes =
        runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_SUCCEEDED_TIMES);
    totalFlushFailedTimes = runtimeCtx.getMetricGroup().counter(COUNTER_TOTAL_FLUSH_FAILED_TIMES);
  }

  public void startAsyncFlushing() {
    final Thread flushThread =
        new Thread(
            () -> {
              while (true) {
                try {
                  if (!asyncFlush()) {
                    LOG.info("doris flush thread is about to exit.");
                    flushThreadAlive = false;
                    break;
                  }
                } catch (Exception e) {
                  flushException = e;
                }
              }
            });
    flushThread.setUncaughtExceptionHandler(
        (t, e) -> {
          LOG.error("dorics flush thread uncaught exception occurred:" + e.getMessage(), e);
          flushException = e;
          flushThreadAlive = false;
        });
    flushThread.setName("doris-flush");
    flushThread.setDaemon(true);
    flushThread.start();
    flushThreadAlive = true;
  }

  public void startScheduler() {
    if (semantic.equals(Semantic.EXACTLY_ONCE)) {
      return;
    }
    stopSchedule();
    this.schedule =
        Executors.newScheduledThreadPool(1, ThreadUtils.threadFactory("doris-interval-sink"));
    this.scheduledFuture =
        this.schedule.schedule(
            () -> {
              synchronized (DorisSinkWriter.this) {
                if (!closed) {
                  try {
                    LOG.info("doris interval sinking trigger");
                    if (bufferMap.isEmpty()) {
                      startScheduler();
                    }
                    flush(null, false);
                  } catch (Exception e) {
                    flushException = e;
                  }
                }
              }
            },
            dorisConfig.flushInterval(),
            TimeUnit.MILLISECONDS);
  }

  private void stopSchedule() {
    if (this.scheduledFuture != null) {
      scheduledFuture.cancel(false);
      this.schedule.shutdown();
    }
  }

  public final synchronized void writeRecords(String database, String table, String... records)
      throws IOException {
    checkFlushException();
    try {
      if (records.length == 0) {
        return;
      }
      final String bufferKey = String.format("%s.%s", database, table);
      final DorisSinkBufferEntry bufferEntity =
          bufferMap.computeIfAbsent(
              bufferKey, k -> new DorisSinkBufferEntry(database, table, dorisConfig.lablePrefix()));
      for (String record : records) {
        byte[] bts = record.getBytes(StandardCharsets.UTF_8);
        bufferEntity.addToBuffer(bts);
      }
      if (Semantic.EXACTLY_ONCE.equals(semantic)) {
        return;
      }
      if (bufferEntity.getBatchCount() >= dorisConfig.sinkMaxRow()
          || bufferEntity.getBatchSize() >= dorisConfig.sinkMaxBytes()) {
        LOG.info(
            String.format(
                "doris buffer Sinking triggered: db: [%s] table: [%s] rows[%d] label[%s].",
                database, table, bufferEntity.getBatchCount(), bufferEntity.getLabel()));
        flush(bufferKey, false);
      }
    } catch (Exception e) {
      throw new IOException("Writing records to doris failed.", e);
    }
  }

  public synchronized void flush(String bufferKey, boolean waitUntilDone) throws Exception {
    if (bufferMap.isEmpty()) {
      flushInternal(null, waitUntilDone);
      return;
    }
    if (null == bufferKey) {
      for (String key : bufferMap.keySet()) {
        flushInternal(key, waitUntilDone);
      }
      return;
    }
    flushInternal(bufferKey, waitUntilDone);
  }

  private synchronized void flushInternal(String bufferKey, boolean waitUntilDone)
      throws Exception {
    checkFlushException();
    if (null == bufferKey || bufferMap.isEmpty() || !bufferMap.containsKey(bufferKey)) {
      if (waitUntilDone) {
        waitAsyncFlushingDone();
      }
      return;
    }
    offer(bufferMap.get(bufferKey));
    bufferMap.remove(bufferKey);
    if (waitUntilDone) {
      // wait the last flush
      waitAsyncFlushingDone();
    }
  }

  private void waitAsyncFlushingDone() throws InterruptedException {
    // wait for previous flushings
    offer(new DorisSinkBufferEntry(null, null, null));
    checkFlushException();
  }

  private void offer(DorisSinkBufferEntry bufferEntity) throws InterruptedException {
    if (!flushThreadAlive) {
      throw new RuntimeException(
          "Flush thread already exit or not start ,please exec  startAsyncFlushing() , ignore offer request for label[%s] ");
    }
    if (!flushQueue.offer(bufferEntity, dorisConfig.sinkOfferTimeout(), TimeUnit.MILLISECONDS)) {
      throw new RuntimeException(
          "Timeout while offering data to flushQueue, exceed "
              + dorisConfig.sinkOfferTimeout()
              + " ms, see "
              + dorisConfig.sinkOption().sinkOfferTimeout().key());
    }
  }

  private boolean asyncFlush() throws Exception {
    final DorisSinkBufferEntry flushData = flushQueue.poll(timeout, TimeUnit.MILLISECONDS);
    if (flushData == null || flushData.getBatchCount() == 0) {
      return true;
    }
    stopSchedule();
    LOG.info(
        String.format(
            "Async stream load: db[%s] table[%s] rows[%d] bytes[%d] label[%s].",
            flushData.getDatabase(),
            flushData.getTable(),
            flushData.getBatchCount(),
            flushData.getBatchSize(),
            flushData.getLabel()));
    long startWithRetries = System.nanoTime();
    for (int i = 0; i < dorisConfig.sinkMaxRetries(); i++) {
      try {
        long start = System.nanoTime();
        streamLoader.doStreamLoad(flushData);
        LOG.info(String.format("Async stream load finished: label[%s].", flushData.getLabel()));
        if (null != totalFlushBytes) {
          totalFlushBytes.inc(flushData.getBatchSize());
          totalFlushRows.inc(flushData.getBatchCount());
          totalFlushTime.inc(System.nanoTime() - startWithRetries);
          totalFlushTimeWithoutRetries.inc(System.nanoTime() - start);
          totalFlushSucceededTimes.inc();
        }
        startScheduler();
        break;
      } catch (Exception e) {
        if (totalFlushFailedTimes != null) {
          totalFlushFailedTimes.inc();
        }
        LOG.warn("Failed to flush batch data to doris, retry times = {}", i, e);
        if (i >= dorisConfig.sinkMaxRetries()) {
          throw e;
        }
        if (e instanceof LoadStatusFailedException
            && ((LoadStatusFailedException) e).needReCreateLabel()) {
          String oldLabel = flushData.getLabel();
          flushData.reGenerateLabel();
          LOG.warn(
              String.format(
                  "Batch label changed from [%s] to [%s]", oldLabel, flushData.getLabel()));
        }
      }
      try {
        Thread.sleep(1000L * (i + 1));
      } catch (InterruptedException ex) {
        Thread.currentThread().interrupt();
        throw new IOException("Unable to flush, interrupted while doing another attempt", ex);
      }
    }
    return true;
  }

  public synchronized void close() throws Exception {
    if (!closed) {
      closed = true;
      LOG.info("Sink is about to close.");
      flush(null, false);
      this.bufferMap.clear();
      if (scheduledFuture != null) {
        scheduledFuture.cancel(false);
        schedule.shutdown();
      }
    }
    checkFlushException();
  }

  private void checkFlushException() {
    if (flushException != null) {
      StackTraceElement[] stack = Thread.currentThread().getStackTrace();
      for (int i = 0; i < stack.length; i++) {
        LOG.info(
            stack[i].getClassName()
                + "."
                + stack[i].getMethodName()
                + " line:"
                + stack[i].getLineNumber());
      }
      throw new RuntimeException("Writing records to doris failed.", flushException);
    }
  }

  public Map<String, DorisSinkBufferEntry> getBufferedBatchMap() {
    return new HashMap<>(bufferMap);
  }

  public void setBufferedBatchMap(Map<String, DorisSinkBufferEntry> newBufferMap) {
    if (Semantic.EXACTLY_ONCE.equals(semantic)) {
      bufferMap.clear();
      bufferMap.putAll(newBufferMap);
    }
  }
}
