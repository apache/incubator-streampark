######################################################
#                                                    #
#               spark process startup.sh             #
#                   user config                      #
#                                                    #
######################################################
#必须设置,执行class的全包名称
spark.app.main=
spark.app.params=
spark.app.id=123
######################################################
#                                                    #
#                spark config                        #
#                                                    #
######################################################
#执行集群设置,不用设置,一般使用YARN
spark.master=yarn
#YARN部署模式
#default=cluster
spark.submit.deployMode=cluster
#spark-streaming每个批次间隔时间
#default=300
spark.batch.duration=300
#spark on yarn的任务提交队列
#default=defalut
spark.yarn.queue=default
#spark 任务名称配置,建议保持任务名称全局唯一
#这样可以在设计任务失败的时候根据名称做一些唯一处理
#不设置使用类全名.App
spark.app.name=
#spark网络序列化方式,默认是JavaSerializer,可针对所有类型但速度较慢
#这里使用推荐的Kryo方式
#kafka-0.10必须使用此方式
spark.serializer=org.apache.spark.serializer.KryoSerializer
#++++++++++++++++++++++Driver节点相关配置+++++++++++++++++++++++++++
#Driver节点使用内存大小设置
#default=512MB
spark.driver.memory=512MB
#Driver节点使用的cpu个数设置
#default=1
spark.driver.cores=1
#Driver节点构建时spark-jar和user-jar冲突时优先使用用户提供的,这是一个实验性质的参数只对cluster模式有效
#default=false
spark.driver.userClassPathFirst=false
#++++++++++++++++++++++Executor节点相关配置+++++++++++++++++++++++++
#Executor个数设置
#default=1
spark.executor.instances=1
#Executor使用cpu个数设置
#default=1
spark.executor.cores=1
#Executor使用内存大小设置
#default=512MB
spark.executor.memory=512MB
#同driver节点配置作用相同,但是是针对executor的
#default=false
spark.executor.userClassPathFirst=true
#++++++++++++++++++++++++Executor动态分配相关配置++++++++++++++++++++
#Executor动态分配的前置服务
#default=false
spark.shuffle.service.enabled=true
#服务对应的端口,此端口服务是配置在yarn-site中的,由NodeManager服务加载启动
#default=7337
spark.shuffle.service.port=7337
#配置是否启用资源动态分配,此动态分配是针对executor的,需要yarn集群配置支持动态分配
#default=false
spark.dynamicAllocation.enabled=true
#释放空闲的executor的时间
#default=60s
spark.dynamicAllocation.executorIdleTimeout=60s
#有缓存的executor空闲释放时间
#default=infinity(默认不释放)
spark.dynamicAllocation.cachedExecutorIdleTimeout=-1
#初始化executor的个数,如果设置spark.executor.instances谁小用谁
#default=minExecutors(不设置使用此项配置值)
spark.dynamicAllocation.initialExecutors=1
#executor动态分配可分配最大数量
#default=infinity
spark.dynamicAllocation.maxExecutors=60
#executor动态收缩的最小数量
#default=0
spark.dynamicAllocation.minExecutors=1
#批次调度延迟多长时间开始增加executor
#default=1s
spark.dynamicAllocation.schedulerBacklogTimeout=1s
#同上,但是是针对之后的请求
#default=SchedulerBacklogTimeout(不设置使用此项配置值)
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s
######################################################
#                                                    #
#             StreamX-Spark Kafka Source             #
#                   base config                      #
#                                                    #
######################################################
#spark.source.kafka.consume后面的配置是标准kafka配置
#kafka消费的topics配置,可以配置多个,每个topic之间用逗号[,]隔开
#default=
spark.source.kafka.consume.topics=
#kafka consumer的group id.
#default=kafka.consumer.001
spark.source.kafka.consume.group.id=kafka.consumer.001
#kafka集群的主机和端口号,可以配置多个,每个主机之间用逗号[,]隔开
#default=
spark.source.kafka.consume.bootstrap.servers=
#第一次消费kafka topic的时候指定从什么位置消费 有两个可选值latest[最新位置],earliest[最早位置]
#default=earliest
spark.source.kafka.consume.auto.offset.reset=earliest
#spark消费kafka的时候如何管理offset 这里可选的值有三种hbase,redis,kafka每种值对应一种存储方式
#default=kafka
spark.source.kafka.offset.store.type=kafka
#自定义spark管理kafka offset的方法,需要指定一个自定义类的名称
#spark.source.kafka.offset.store.class=none
#新版本kafka使用的key序列化方式
#default=java.Serialization
spark.source.kafka.consume.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#最新版kafka使用的value序列化方式
#default=java.Serialization
spark.source.kafka.consume.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#获取一次数据的最大长度,此值的大小需要kafka server端支持
#default=10485760
spark.source.kafka.consume.max.partition.fetch.bytes=10485760
#获取一次数据请求的最大等待时间
#default=3000
spark.source.kafka.consume.fetch.max.wait.ms=3000
######################################################
#                                                    #
#              StreamX-Spark Redis Sink              #
#                   base config                      #
#                                                    #
######################################################
#StreamX redis sink需要的几个配置
#redis主机
spark.sink.redis.host=
#redis端口
spark.sink.redis.port=6379
#redis数据库
spark.sink.redis.db=0
#redis连接超时时间
spark.sink.redis.timeout=30
######################################################
#                                                    #
#                StreamX-Spark Monitor               #
#              Congestion base config                #
#                                                    #
######################################################
#StreamX 自带的拥堵监控需要的几个参数
#堆积了几个批次之后开始告警,默认是0不告警
#default=0
spark.monitor.congestion.batch=0
#堆积多少个批次之后kill掉任务,默认是0不kill,配合任务自动重启功能可有效重启堆积任务使恢复
#default=0
spark.monitor.suicide.batch=0
#zk地址
spark.monitor.zookeeper=zookeeper://127.0.0.1:2181
#钉钉机器人发送消息的api地址,需要从http开头的全路径
spark.monitor.dingding.url=https://oapi.dingtalk.com/robot/send?access_token=d4d19790b4d4b83bfbeeb9f67e75ed5b1c2e3a40968e9d908df7c691c0f78afe
#要@的手机号
spark.monitor.dingding.user=

