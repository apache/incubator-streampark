######################################################
#                                                    #
#               spark process startup.sh             #
#                   user config                      #
#                                                    #
######################################################
#必须设置,执行class的全包名称
spark.main.class=com.streamx.spark.test.HelloStreamXApp
#spark 任务名称配置,建议保持任务名称全局唯一
#这样可以在设计任务失败的时候根据名称做一些唯一处理
#不设置使用类全名.App
spark.app.name=HelloStreamXApp
spark.app.conf.version=10

######################################################
#                                                    #
#                spark config                        #
#                                                    #
######################################################
#执行集群设置,不用设置,一般使用YARN
spark.master=yarn
#YARN部署模式
#default=cluster
spark.submit.deployMode=cluster
#spark-streaming每个批次间隔时间
#default=300
spark.batch.duration=5
#spark on yarn的任务提交队列
#default=defalut
spark.yarn.queue=default
#spark网络序列化方式,默认是JavaSerializer,可针对所有类型但速度较慢
#这里使用推荐的Kryo方式
#kafka-0.10必须使用此方式
spark.serializer=org.apache.spark.serializer.KryoSerializer
#++++++++++++++++++++++Driver节点相关配置+++++++++++++++++++++++++++
#Driver节点使用内存大小设置
#default=512MB
spark.driver.memory=512MB
#Driver节点使用的cpu个数设置
#default=1
spark.driver.cores=1
#Driver节点构建时spark-jar和user-jar冲突时优先使用用户提供的,这是一个实验性质的参数只对cluster模式有效
#default=false
spark.driver.userClassPathFirst=false
#++++++++++++++++++++++Executor节点相关配置+++++++++++++++++++++++++
#Executor个数设置
#default=1
spark.executor.instances=1
#Executor使用cpu个数设置
#default=1
spark.executor.cores=1
#Executor使用内存大小设置
#default=512MB
spark.executor.memory=512MB
#同driver节点配置作用相同,但是是针对executor的
#default=false
spark.executor.userClassPathFirst=true
#++++++++++++++++++++++++Executor动态分配相关配置++++++++++++++++++++
#Executor动态分配的前置服务
#default=false
spark.shuffle.service.enabled=true
#服务对应的端口,此端口服务是配置在yarn-site中的,由NodeManager服务加载启动
#default=7337
spark.shuffle.service.port=7337
#配置是否启用资源动态分配,此动态分配是针对executor的,需要yarn集群配置支持动态分配
#default=false
spark.dynamicAllocation.enabled=true
#释放空闲的executor的时间
#default=60s
spark.dynamicAllocation.executorIdleTimeout=60s
#有缓存的executor空闲释放时间
#default=infinity(默认不释放)
spark.dynamicAllocation.cachedExecutorIdleTimeout=-1
#初始化executor的个数,如果设置spark.executor.instances谁小用谁
#default=minExecutors(不设置使用此项配置值)
spark.dynamicAllocation.initialExecutors=1
#executor动态分配可分配最大数量
#default=infinity
spark.dynamicAllocation.maxExecutors=60
#executor动态收缩的最小数量
#default=0
spark.dynamicAllocation.minExecutors=1
#批次调度延迟多长时间开始增加executor
#default=1s
spark.dynamicAllocation.schedulerBacklogTimeout=1s
#同上,但是是针对之后的请求
#default=SchedulerBacklogTimeout(不设置使用此项配置值)
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s

######################################################
#                                                    #
#             StreamX-Spark Kafka Source             #
#                   base config                      #
#                                                    #
######################################################
spark.source.kafka.consume.topics=bigdata
spark.source.kafka.consume.group.id=test
spark.source.kafka.consume.bootstrap.servers=localhost:9091,localhost:9092,localhost:9093
spark.source.kafka.consume.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.source.kafka.consume.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.source.kafka.consume.fetch.max.wait.ms=3000
spark.source.kafka.consume.repartition=60
#第一次消费kafka topic的时候指定从什么位置消费 有两个可选值latest[最新位置],earliest[最早位置]
spark.source.kafka.consume.auto.offset.reset=earliest
spark.source.kafka.offset.store.type=mysql
spark.source.kafka.offset.store.mysql.table=consumer_offsets
spark.source.kafka.offset.store.mysql.jdbc.url=jdbc:mysql://localhost:3306/spark
spark.source.kafka.offset.store.mysql.user=root
spark.source.kafka.offset.store.mysql.password=123456

######################################################
#                                                    #
#              StreamX-Spark MySQL Sink              #
#                   base config                      #
#                                                    #
######################################################
spark.sink.mysql.jdbc.url=jdbc:mysql://localhost:3306/spark
spark.sink.mysql.user=root
spark.sink.mysql.password=123456
######################################################
#                                                    #
#                StreamX-Spark Monitor               #
#              Congestion base config                #
#                                                    #
######################################################
#StreamX 自带的拥堵监控需要的几个参数
#堆积了几个批次之后开始告警,默认是0不告警
#default=0
spark.monitor.congestion.batch=0
#堆积多少个批次之后kill掉任务,默认是0不kill,配合任务自动重启功能可有效重启堆积任务使恢复
#default=0
spark.monitor.suicide.batch=0
#zk地址
spark.monitor.zookeeper=localhost:2181
#spark.monitor.dingding.url=https://oapi.dingtalk.com/robot/send?access_token=d4d19790b4d4b83bfbeeb9f67e75ed5b1c2e3a40968e9d908df7c691c0f78afe
spark.monitor.dingding.user=
