mysql:
  driverClassName: com.mysql.jdbc.Driver
  jdbcUrl: jdbc:mysql://localhost:3306/test
  username: root
  password: 123322242
  batch.size: 100

# hbase
hbase:
  zookeeper.quorum: test-hadoop-1,test-hadoop-2,test-hadoop-6
  zookeeper.property.clientPort: 2181

#clickhouse
clickhouse.sink:
  driverClassName:
  jdbcUrl: http://192.168.0.100:8123
  username: default
  password: 123322242
  threshold:
    bufferSize: 100
    numWriters: 3
    queueCapacity: 100
    timeout: 1000
    successCode: 200
    retries: 10 #一条记录当插入失败时重试的最大次数
  failover:
    storage: hdfs #kafka,hbase,hdfs
    mysql: # 保存类型为MySQL,将失败的数据保存到MySQL
      jdbcUrl: jdbc:mysql://localhost:3306/test
      username: root
      password: 123322242
    kafka:
      topic: bigdata
      bootstrap.servers: localhost:9091,localhost:9092,localhost:9093
    hbase:
      zookeeper.quorum: localhost
      zookeeper.property.clientPort: 2181
    hdfs:
      namenode: hdfs://localhost:8020 # namenode rpc address and port, e.g: hdfs://hadoop:8020 , hdfs://hadoop:9000
      user: benjobs # user
      path: /clickhouse/failover # save path
      format: yyyy-MM-dd

http.sink:
  threshold:
    numWriters: 3
    queueCapacity: 10000 #队列最大容量,视单条记录大小而自行估量队列大小,如值太大,上游数据源来的太快,下游写入数据跟不上可能会OOM.
    timeout: 100 #发送http请求的超时时间
    retries: 3 #发送失败时的最大重试次数
    successCode: 200 #发送成功状态码,这里可以有多个值,用","号分隔
  failover:
    table: record
    storage: mysql #kafka,hbase,hdfs
    mysql: # 保存类型为MySQL,将失败的数据保存到MySQL
      jdbcUrl: jdbc:mysql://localhost:3306/test
      username: root
      password: 123322242
    kafka:
      topic: bigdata
      bootstrap.servers: localhost:9091,localhost:9092,localhost:9093
    hbase:
      zookeeper.quorum: localhost
      zookeeper.property.clientPort: 2181
    hdfs:
      namenode: hdfs://localhost:8020 # namenode rpc address and port, e.g: hdfs://hadoop:8020 , hdfs://hadoop:9000
      user: benjobs # user
      path: /clickhouse/failover # save path
      format: yyyy-MM-dd
