#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

######################################################
#                                                    #
#               spark process startup.sh             #
#                   user config                      #
#                                                    #
######################################################
#\u5FC5\u987B\u8BBE\u7F6E,\u6267\u884Cclass\u7684\u5168\u5305\u540D\u79F0
spark.main.class=org.apache.streampark.spark.test.HelloStreamParkApp
#spark \u4EFB\u52A1\u540D\u79F0\u914D\u7F6E,\u5EFA\u8BAE\u4FDD\u6301\u4EFB\u52A1\u540D\u79F0\u5168\u5C40\u552F\u4E00
#\u8FD9\u6837\u53EF\u4EE5\u5728\u8BBE\u8BA1\u4EFB\u52A1\u5931\u8D25\u7684\u65F6\u5019\u6839\u636E\u540D\u79F0\u505A\u4E00\u4E9B\u552F\u4E00\u5904\u7406
#\u4E0D\u8BBE\u7F6E\u4F7F\u7528\u7C7B\u5168\u540D.App
spark.app.name=HelloStreamParkApp
spark.app.conf.version=10

######################################################
#                                                    #
#                spark config                        #
#                                                    #
######################################################
#\u6267\u884C\u96C6\u7FA4\u8BBE\u7F6E,\u4E0D\u7528\u8BBE\u7F6E,\u4E00\u822C\u4F7F\u7528YARN
spark.master=yarn
#YARN\u90E8\u7F72\u6A21\u5F0F
#default=cluster
spark.submit.deployMode=cluster
#spark-streaming\u6BCF\u4E2A\u6279\u6B21\u95F4\u9694\u65F6\u95F4
#default=300
spark.batch.duration=5
#spark on yarn\u7684\u4EFB\u52A1\u63D0\u4EA4\u961F\u5217
#default=defalut
spark.yarn.queue=default
#spark\u7F51\u7EDC\u5E8F\u5217\u5316\u65B9\u5F0F,\u9ED8\u8BA4\u662FJavaSerializer,\u53EF\u9488\u5BF9\u6240\u6709\u7C7B\u578B\u4F46\u901F\u5EA6\u8F83\u6162
#\u8FD9\u91CC\u4F7F\u7528\u63A8\u8350\u7684Kryo\u65B9\u5F0F
#kafka-0.10\u5FC5\u987B\u4F7F\u7528\u6B64\u65B9\u5F0F
spark.serializer=org.apache.spark.serializer.KryoSerializer
#++++++++++++++++++++++Driver\u8282\u70B9\u76F8\u5173\u914D\u7F6E+++++++++++++++++++++++++++
#Driver\u8282\u70B9\u4F7F\u7528\u5185\u5B58\u5927\u5C0F\u8BBE\u7F6E
#default=512MB
spark.driver.memory=512MB
#Driver\u8282\u70B9\u4F7F\u7528\u7684cpu\u4E2A\u6570\u8BBE\u7F6E
#default=1
spark.driver.cores=1
#Driver\u8282\u70B9\u6784\u5EFA\u65F6spark-jar\u548Cuser-jar\u51B2\u7A81\u65F6\u4F18\u5148\u4F7F\u7528\u7528\u6237\u63D0\u4F9B\u7684,\u8FD9\u662F\u4E00\u4E2A\u5B9E\u9A8C\u6027\u8D28\u7684\u53C2\u6570\u53EA\u5BF9cluster\u6A21\u5F0F\u6709\u6548
#default=false
spark.driver.userClassPathFirst=false
#++++++++++++++++++++++Executor\u8282\u70B9\u76F8\u5173\u914D\u7F6E+++++++++++++++++++++++++
#Executor\u4E2A\u6570\u8BBE\u7F6E
#default=1
spark.executor.instances=1
#Executor\u4F7F\u7528cpu\u4E2A\u6570\u8BBE\u7F6E
#default=1
spark.executor.cores=1
#Executor\u4F7F\u7528\u5185\u5B58\u5927\u5C0F\u8BBE\u7F6E
#default=512MB
spark.executor.memory=512MB
#\u540Cdriver\u8282\u70B9\u914D\u7F6E\u4F5C\u7528\u76F8\u540C,\u4F46\u662F\u662F\u9488\u5BF9executor\u7684
#default=false
spark.executor.userClassPathFirst=true
#++++++++++++++++++++++++Executor\u52A8\u6001\u5206\u914D\u76F8\u5173\u914D\u7F6E++++++++++++++++++++
#Executor\u52A8\u6001\u5206\u914D\u7684\u524D\u7F6E\u670D\u52A1
#default=false
spark.shuffle.service.enabled=true
#\u670D\u52A1\u5BF9\u5E94\u7684\u7AEF\u53E3,\u6B64\u7AEF\u53E3\u670D\u52A1\u662F\u914D\u7F6E\u5728yarn-site\u4E2D\u7684,\u7531NodeManager\u670D\u52A1\u52A0\u8F7D\u542F\u52A8
#default=7337
spark.shuffle.service.port=7337
#\u914D\u7F6E\u662F\u5426\u542F\u7528\u8D44\u6E90\u52A8\u6001\u5206\u914D,\u6B64\u52A8\u6001\u5206\u914D\u662F\u9488\u5BF9executor\u7684,\u9700\u8981yarn\u96C6\u7FA4\u914D\u7F6E\u652F\u6301\u52A8\u6001\u5206\u914D
#default=false
spark.dynamicAllocation.enabled=true
#\u91CA\u653E\u7A7A\u95F2\u7684executor\u7684\u65F6\u95F4
#default=60s
spark.dynamicAllocation.executorIdleTimeout=60s
#\u6709\u7F13\u5B58\u7684executor\u7A7A\u95F2\u91CA\u653E\u65F6\u95F4
#default=infinity(\u9ED8\u8BA4\u4E0D\u91CA\u653E)
spark.dynamicAllocation.cachedExecutorIdleTimeout=30
#\u521D\u59CB\u5316executor\u7684\u4E2A\u6570,\u5982\u679C\u8BBE\u7F6Espark.executor.instances\u8C01\u5C0F\u7528\u8C01
#default=minExecutors(\u4E0D\u8BBE\u7F6E\u4F7F\u7528\u6B64\u9879\u914D\u7F6E\u503C)
spark.dynamicAllocation.initialExecutors=1
#executor\u52A8\u6001\u5206\u914D\u53EF\u5206\u914D\u6700\u5927\u6570\u91CF
#default=infinity
spark.dynamicAllocation.maxExecutors=60
#executor\u52A8\u6001\u6536\u7F29\u7684\u6700\u5C0F\u6570\u91CF
#default=0
spark.dynamicAllocation.minExecutors=1
#\u6279\u6B21\u8C03\u5EA6\u5EF6\u8FDF\u591A\u957F\u65F6\u95F4\u5F00\u59CB\u589E\u52A0executor
#default=1s
spark.dynamicAllocation.schedulerBacklogTimeout=1s
#\u540C\u4E0A,\u4F46\u662F\u662F\u9488\u5BF9\u4E4B\u540E\u7684\u8BF7\u6C42
#default=SchedulerBacklogTimeout(\u4E0D\u8BBE\u7F6E\u4F7F\u7528\u6B64\u9879\u914D\u7F6E\u503C)
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s

######################################################
#                                                    #
#             StreamPark-Spark Kafka Source             #
#                   base config                      #
#                                                    #
######################################################
spark.source.kafka.consume.topics=bigdata
spark.source.kafka.consume.group.id=test
spark.source.kafka.consume.bootstrap.servers=kafka1:9092
spark.source.kafka.consume.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.source.kafka.consume.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.source.kafka.consume.fetch.max.wait.ms=3000
spark.source.kafka.consume.repartition=60
#\u7B2C\u4E00\u6B21\u6D88\u8D39kafka topic\u7684\u65F6\u5019\u6307\u5B9A\u4ECE\u4EC0\u4E48\u4F4D\u7F6E\u6D88\u8D39 \u6709\u4E24\u4E2A\u53EF\u9009\u503Clatest[\u6700\u65B0\u4F4D\u7F6E],earliest[\u6700\u65E9\u4F4D\u7F6E]
spark.source.kafka.consume.auto.offset.reset=earliest
spark.source.kafka.offset.store.type=mysql
spark.source.kafka.offset.store.mysql.table=consumer_offsets
spark.source.kafka.offset.store.mysql.jdbc.url=jdbc:mysql://localhost:3306/spark
spark.source.kafka.offset.store.mysql.user=root
spark.source.kafka.offset.store.mysql.password=123456

######################################################
#                                                    #
#              StreamPark-Spark MySQL Sink              #
#                   base config                      #
#                                                    #
######################################################
spark.sink.mysql.jdbc.url=jdbc:mysql://localhost:3306/spark
spark.sink.mysql.user=root
spark.sink.mysql.password=123456
######################################################
#                                                    #
#                StreamPark-Spark Monitor               #
#              Congestion base config                #
#                                                    #
######################################################
#default=0
spark.monitor.congestion.batch=0
#\u5806\u79EF\u591A\u5C11\u4E2A\u6279\u6B21\u4E4B\u540Ekill\u6389\u4EFB\u52A1,\u9ED8\u8BA4\u662F0\u4E0Dkill,\u914D\u5408\u4EFB\u52A1\u81EA\u52A8\u91CD\u542F\u529F\u80FD\u53EF\u6709\u6548\u91CD\u542F\u5806\u79EF\u4EFB\u52A1\u4F7F\u6062\u590D
#default=0
spark.monitor.suicide.batch=0
#zk\u5730\u5740
spark.monitor.zookeeper=localhost:2181
#spark.monitor.dingding.url=https://oapi.dingtalk.com/robot/send?access_token=d4d19790b4d4b83bfbeeb9f67e75ed5b1c2e3a40968e9d908df7c691c0f78afe
spark.monitor.dingding.user=
