/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.streampark.console.core.entity;

import org.apache.streampark.common.conf.FlinkVersion;
import org.apache.streampark.common.util.DeflaterUtils;
import org.apache.streampark.common.util.PropertiesUtils;
import org.apache.streampark.console.base.exception.ApiAlertException;
import org.apache.streampark.console.base.exception.ApiDetailException;

import org.apache.commons.io.FileUtils;
import org.apache.commons.lang3.StringUtils;

import com.baomidou.mybatisplus.annotation.IdType;
import com.baomidou.mybatisplus.annotation.TableId;
import com.baomidou.mybatisplus.annotation.TableName;
import com.fasterxml.jackson.annotation.JsonIgnore;
import lombok.Data;

import java.io.File;
import java.io.Serializable;
import java.nio.charset.StandardCharsets;
import java.util.Date;
import java.util.Map;
import java.util.Properties;

@Data
@TableName("t_flink_env")
public class FlinkEnv implements Serializable {

  @TableId(type = IdType.AUTO)
  private Long id;

  private String flinkName;

  private String flinkHome;

  private String flinkConf;

  private String description;

  private String scalaVersion;

  private String version;

  /** is default */
  private Boolean isDefault;

  private Date createTime;

  private transient FlinkVersion flinkVersion;

  private transient String versionOfLarge;

  private transient String versionOfMiddle;

  private transient String versionOfLast;

  private transient String streamParkScalaVersion = scala.util.Properties.versionNumberString();

  public void doSetFlinkConf() throws ApiDetailException {

    File yaml;
    float ver = Float.parseFloat(getVersionOfFirst().concat(".").concat(getVersionOfMiddle()));
    if (ver < 1.19f) {
      yaml = new File(this.flinkHome.concat("/conf/flink-conf.yaml"));
      if (!yaml.exists()) {
        throw new ApiAlertException("cannot find flink-conf.yaml in flink/conf ");
      }
    } else if (ver == 1.19f) {
      yaml = new File(this.flinkHome.concat("/conf/flink-conf.yaml"));
      if (!yaml.exists()) {
        yaml = new File(this.flinkHome.concat("/conf/config.yaml"));
      }
      if (!yaml.exists()) {
        throw new ApiAlertException("cannot find config.yaml|flink-conf.yaml in flink/conf ");
      }
    } else {
      yaml = new File(this.flinkHome.concat("/conf/config.yaml"));
      if (!yaml.exists()) {
        throw new ApiAlertException("cannot find config.yaml in flink/conf ");
      }
    }
    try {
      String flinkConf = FileUtils.readFileToString(yaml, StandardCharsets.UTF_8);
      this.flinkConf = DeflaterUtils.zipString(flinkConf);
    } catch (Exception e) {
      throw new ApiDetailException(e);
    }
  }

  public void doSetVersion() {
    this.setVersion(this.getFlinkVersion().version());
    this.setScalaVersion(this.getFlinkVersion().scalaVersion());
    if (!streamParkScalaVersion.startsWith(this.getFlinkVersion().scalaVersion())) {
      throw new UnsupportedOperationException(
          String.format(
              "The current Scala version of StreamPark is %s, but the scala version of Flink to be added is %s, which does not match, Please check",
              streamParkScalaVersion, this.getFlinkVersion().scalaVersion()));
    }
  }

  public Map<String, String> convertFlinkYamlAsMap() {
    String flinkYamlString = DeflaterUtils.unzipString(flinkConf);
    return PropertiesUtils.loadFlinkConfYaml(flinkYamlString);
  }

  @JsonIgnore
  public FlinkVersion getFlinkVersion() {
    if (this.flinkVersion == null) {
      this.flinkVersion = new FlinkVersion(this.flinkHome);
    }
    return this.flinkVersion;
  }

  public void unzipFlinkConf() {
    this.flinkConf = DeflaterUtils.unzipString(this.flinkConf);
  }

  public String getLargeVersion() {
    if (StringUtils.isNotBlank(this.version)) {
      return this.version.substring(0, this.version.lastIndexOf("."));
    }
    return null;
  }

  public String getVersionOfFirst() {
    if (StringUtils.isNotBlank(this.version)) {
      return this.version.split("\\.")[0];
    }
    return null;
  }

  public String getVersionOfMiddle() {
    if (StringUtils.isNotBlank(this.version)) {
      return this.version.split("\\.")[1];
    }
    return null;
  }

  public String getVersionOfLast() {
    if (StringUtils.isNotBlank(this.version)) {
      return this.version.split("\\.")[2];
    }
    return null;
  }

  @JsonIgnore
  public Properties getFlinkConfig() {
    String flinkYamlString = DeflaterUtils.unzipString(flinkConf);
    Properties flinkConfig = new Properties();
    Map<String, String> config = PropertiesUtils.loadFlinkConfYaml(flinkYamlString);
    flinkConfig.putAll(config);
    return flinkConfig;
  }
}
